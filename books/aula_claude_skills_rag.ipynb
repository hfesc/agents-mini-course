{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "424fa1a4",
   "metadata": {},
   "source": [
    "# Claude Skills - Document Understanding com RAG\n",
    "\n",
    "Este notebook demonstra como usar RAG (Retrieval Augmented Generation) para fazer perguntas sobre a documentação do Claude Skills do Anthropic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90146bcf",
   "metadata": {},
   "source": [
    "## Setup e Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcf1806d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain langchain-community langchain-openai langchain-text-splitters langchain-core chromadb beautifulsoup4 python-dotenv tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68854c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d152f204",
   "metadata": {},
   "source": [
    "## Carregando Documento do GitHub\n",
    "\n",
    "Vamos carregar o README.md do repositório Claude Skills da Anthropic usando o WebBaseLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad9825f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# URL do README do Claude Skills\n",
    "url = \"https://raw.githubusercontent.com/anthropics/skills/main/README.md\"\n",
    "\n",
    "loader = WebBaseLoader(url)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adaf50c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de documentos carregados: 1\n",
      "\n",
      "Tamanho do documento: 7632 caracteres\n",
      "\n",
      "Primeiros 500 caracteres:\n",
      "# Skills\n",
      "Skills are folders of instructions, scripts, and resources that Claude loads dynamically to improve performance on specialized tasks. Skills teach Claude how to complete specific tasks in a repeatable way, whether that's creating documents with your company's brand guidelines, analyzing data using your organization's specific workflows, or automating personal tasks.\n",
      "\n",
      "For more information, check out:\n",
      "- [What are skills?](https://support.claude.com/en/articles/12512176-what-are-skills)\n",
      "- \n"
     ]
    }
   ],
   "source": [
    "# Verificar o conteúdo carregado\n",
    "print(f\"Número de documentos carregados: {len(docs)}\")\n",
    "print(f\"\\nTamanho do documento: {len(docs[0].page_content)} caracteres\")\n",
    "print(f\"\\nPrimeiros 500 caracteres:\\n{docs[0].page_content[:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5432ea0",
   "metadata": {},
   "source": [
    "## Divisão do Documento (Text Splitting)\n",
    "\n",
    "Dividimos o documento em chunks menores para melhorar a recuperação de informações relevantes.\n",
    "**MELHORIAS**: Chunks menores (800) com overlap maior (200) para manter mais contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "006d15cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Parâmetros otimizados para melhor recuperação\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,        # Reduzido de 1500 para 800\n",
    "    chunk_overlap=200,     # Aumentado de 150 para 200\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],  # Prioriza quebras naturais\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5db793c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de chunks criados: 12\n",
      "\n",
      "Primeiro chunk:\n",
      "# Skills\n",
      "Skills are folders of instructions, scripts, and resources that Claude loads dynamically to improve performance on specialized tasks. Skills teach Claude how to complete specific tasks in a repeatable way, whether that's creating documents with your company's brand guidelines, analyzing data using your organization's specific workflows, or automating personal tasks.\n",
      "\n",
      "Último chunk:\n",
      "The markdown content below contains the instructions, examples, and guidelines that Claude will follow. For more details, see [How to create custom skills](https://support.claude.com/en/articles/12512198-creating-custom-skills).\n",
      "\n",
      "# Partner Skills\n",
      "\n",
      "Skills are a great way to teach Claude how to get better at using specific pieces of software. As we see awesome example skills from partners, we may highlight some of them here:\n",
      "\n",
      "- **Notion** - [Notion Skills for Claude](https://www.notion.so/notiondevs/Notion-Skills-for-Claude-28da4445d27180c7af1df7d8615723d0)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Número de chunks criados: {len(splits)}\")\n",
    "print(f\"\\nPrimeiro chunk:\\n{splits[0].page_content}\")\n",
    "print(f\"\\nÚltimo chunk:\\n{splits[-1].page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e3417",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "Vamos criar embeddings usando OpenAI para representar os chunks de texto em formato vetorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5560df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # Modelo mais recente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffded5fc",
   "metadata": {},
   "source": [
    "## Criando o Vectorstore\n",
    "\n",
    "Armazenamos os embeddings no ChromaDB para realizar buscas por similaridade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6eba7425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "import os\n",
    "\n",
    "persist_directory = '../out/chroma_claude_skills/'\n",
    "\n",
    "# Criar diretório se não existir\n",
    "os.makedirs(persist_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48d7a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove banco de dados antigo se existir e recria o diretório\n",
    "!rm -rf ../out/chroma_claude_skills/\n",
    "!mkdir -p ../out/chroma_claude_skills/\n",
    "!chmod 777 ../out/chroma_claude_skills/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84faaeee",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Query error: Database error: error returned from database: (code: 1032) attempt to write a readonly database",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      6\u001b[39m chroma_client = chromadb.PersistentClient(\n\u001b[32m      7\u001b[39m     path=persist_directory,\n\u001b[32m      8\u001b[39m     settings=Settings(\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     )\n\u001b[32m     12\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Criar collection\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m vectordb = \u001b[43mChroma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchroma_client\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:887\u001b[39m, in \u001b[36mChroma.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m    885\u001b[39m texts = [doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m    886\u001b[39m metadatas = [doc.metadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:843\u001b[39m, in \u001b[36mChroma.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m    835\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbatch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[32m    837\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[32m    838\u001b[39m         api=chroma_collection._client,\n\u001b[32m    839\u001b[39m         ids=ids,\n\u001b[32m    840\u001b[39m         metadatas=metadatas,\n\u001b[32m    841\u001b[39m         documents=texts,\n\u001b[32m    842\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m         \u001b[43mchroma_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    849\u001b[39m     chroma_collection.add_texts(texts=texts, metadatas=metadatas, ids=ids)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:299\u001b[39m, in \u001b[36mChroma.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    297\u001b[39m ids_with_metadata = [ids[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m non_empty_ids]\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids_with_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    306\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mExpected metadata value to be\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/chromadb/api/models/Collection.py:455\u001b[39m, in \u001b[36mCollection.upsert\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    435\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001b[39;00m\n\u001b[32m    436\u001b[39m \n\u001b[32m    437\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    444\u001b[39m \u001b[33;03m    None\u001b[39;00m\n\u001b[32m    445\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    446\u001b[39m upsert_request = \u001b[38;5;28mself\u001b[39m._validate_and_prepare_upsert_request(\n\u001b[32m    447\u001b[39m     ids=ids,\n\u001b[32m    448\u001b[39m     embeddings=embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m    452\u001b[39m     uris=uris,\n\u001b[32m    453\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_upsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupsert_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupsert_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43membeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupsert_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadatas\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupsert_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupsert_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muris\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/chromadb/api/rust.py:482\u001b[39m, in \u001b[36mRustBindingsAPI._upsert\u001b[39m\u001b[34m(self, collection_id, ids, embeddings, metadatas, documents, uris, tenant, database)\u001b[39m\n\u001b[32m    470\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_upsert\u001b[39m(\n\u001b[32m    472\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    480\u001b[39m     database: \u001b[38;5;28mstr\u001b[39m = DEFAULT_DATABASE,\n\u001b[32m    481\u001b[39m ) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m482\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbindings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mInternalError\u001b[39m: Query error: Database error: error returned from database: (code: 1032) attempt to write a readonly database"
     ]
    }
   ],
   "source": [
    "# Criar vectorstore com configurações específicas para evitar problemas de permissão\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Criar cliente com configurações personalizadas\n",
    "chroma_client = chromadb.PersistentClient(\n",
    "    path=persist_directory,\n",
    "    settings=Settings(\n",
    "        anonymized_telemetry=False,\n",
    "        allow_reset=True\n",
    "    )\n",
    ")\n",
    "\n",
    "# Criar collection\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory,\n",
    "    client=chroma_client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338df0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Número de documentos no vectorstore: {vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef875ee",
   "metadata": {},
   "source": [
    "## Testes de Similarity Search\n",
    "\n",
    "Agora vamos fazer perguntas sobre Claude Skills e validar se as respostas estão alinhadas com o contexto do documento original.\n",
    "**MELHORIA**: Aumentado k=5 para recuperar mais documentos relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fc8889",
   "metadata": {},
   "source": [
    "### Pergunta 1: O que é Claude Skills?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c78e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = \"What is Claude Skills?\"\n",
    "docs_q1 = vectordb.similarity_search(question1, k=5)  # Aumentado de 3 para 5\n",
    "\n",
    "print(f\"Pergunta: {question1}\")\n",
    "print(f\"\\nNúmero de documentos recuperados: {len(docs_q1)}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "for i, doc in enumerate(docs_q1, 1):\n",
    "    print(f\"\\nDocumento {i}:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb08e43",
   "metadata": {},
   "source": [
    "### Pergunta 2: Como instalar Claude Skills?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e113fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question2 = \"How do I install Claude Skills?\"\n",
    "docs_q2 = vectordb.similarity_search(question2, k=5)\n",
    "\n",
    "print(f\"Pergunta: {question2}\")\n",
    "print(f\"\\nNúmero de documentos recuperados: {len(docs_q2)}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "for i, doc in enumerate(docs_q2, 1):\n",
    "    print(f\"\\nDocumento {i}:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707bf994",
   "metadata": {},
   "source": [
    "### Pergunta 3: Quais são as principais funcionalidades (skills) disponíveis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f93f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question3 = \"What skills are available in Claude Skills?\"\n",
    "docs_q3 = vectordb.similarity_search(question3, k=5)\n",
    "\n",
    "print(f\"Pergunta: {question3}\")\n",
    "print(f\"\\nNúmero de documentos recuperados: {len(docs_q3)}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "for i, doc in enumerate(docs_q3, 1):\n",
    "    print(f\"\\nDocumento {i}:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28c9f52",
   "metadata": {},
   "source": [
    "### Pergunta 4: Como contribuir para o projeto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af3110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question4 = \"How can I contribute to Claude Skills?\"\n",
    "docs_q4 = vectordb.similarity_search(question4, k=5)\n",
    "\n",
    "print(f\"Pergunta: {question4}\")\n",
    "print(f\"\\nNúmero de documentos recuperados: {len(docs_q4)}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "for i, doc in enumerate(docs_q4, 1):\n",
    "    print(f\"\\nDocumento {i}:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a4bd17",
   "metadata": {},
   "source": [
    "### Pergunta 5: Quais são os requisitos do sistema?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1480762",
   "metadata": {},
   "outputs": [],
   "source": [
    "question5 = \"What are the system requirements for Claude Skills?\"\n",
    "docs_q5 = vectordb.similarity_search(question5, k=5)\n",
    "\n",
    "print(f\"Pergunta: {question5}\")\n",
    "print(f\"\\nNúmero de documentos recuperados: {len(docs_q5)}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "for i, doc in enumerate(docs_q5, 1):\n",
    "    print(f\"\\nDocumento {i}:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90fcd18",
   "metadata": {},
   "source": [
    "## Validação com RAG Completo\n",
    "\n",
    "Vamos usar um LLM para gerar respostas baseadas no contexto recuperado.\n",
    "**MELHORIAS**: \n",
    "- Modelo GPT-4 para respostas mais precisas\n",
    "- Prompt customizado para instruir o modelo\n",
    "- Retriever com MMR para diversidade de documentos\n",
    "- Usando LCEL (LangChain Expression Language) - abordagem moderna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda553fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Usar GPT-4 para respostas mais precisas (ou gpt-3.5-turbo se preferir economizar)\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Template de prompt customizado\n",
    "template = \"\"\"Use os seguintes trechos de contexto para responder a pergunta no final.\n",
    "Se você não sabe a resposta com base no contexto fornecido, diga que não sabe, não tente inventar uma resposta.\n",
    "Seja específico e detalhado na sua resposta, citando informações do contexto quando relevante.\n",
    "Se a pergunta for sobre exemplos ou instruções, forneça-os de forma clara e estruturada.\n",
    "\n",
    "Contexto:\n",
    "{context}\n",
    "\n",
    "Pergunta: {question}\n",
    "\n",
    "Resposta detalhada:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Usar MMR (Maximal Marginal Relevance) para diversidade nos documentos recuperados\n",
    "retriever = vectordb.as_retriever(\n",
    "    search_type=\"mmr\",  # Mudança importante: MMR ao invés de similarity\n",
    "    search_kwargs={\n",
    "        \"k\": 5,          # Recuperar 5 documentos\n",
    "        \"fetch_k\": 10    # Buscar 10 candidatos antes de aplicar MMR\n",
    "    }\n",
    ")\n",
    "\n",
    "# Função auxiliar para formatar documentos\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Criar a chain usando LCEL (LangChain Expression Language)\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4703697e",
   "metadata": {},
   "source": [
    "### Testando com perguntas e validando respostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0ee75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_and_validate(question):\n",
    "    \"\"\"\n",
    "    Faz uma pergunta ao sistema RAG e mostra a resposta com as fontes.\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(f\"PERGUNTA: {question}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Obter resposta\n",
    "    answer = rag_chain.invoke(question)\n",
    "    \n",
    "    # Obter documentos fonte\n",
    "    source_docs = retriever.invoke(question)\n",
    "    \n",
    "    print(f\"\\nRESPOSTA:\\n{answer}\")\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"DOCUMENTOS FONTE:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i, doc in enumerate(source_docs, 1):\n",
    "        print(f\"\\nFonte {i}:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(doc.page_content[:500] + \"...\" if len(doc.page_content) > 500 else doc.page_content)\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    return {\"answer\": answer, \"sources\": source_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6412f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste 1: Conceito geral\n",
    "result1 = ask_and_validate(\"What is Claude Skills and what is its main purpose?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8435858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste 2: Instalação\n",
    "result2 = ask_and_validate(\"How do I install and set up Claude Skills?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ba6d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste 3: Funcionalidades\n",
    "result3 = ask_and_validate(\"What are the main features and capabilities of Claude Skills?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d290f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste 4: Contribuição\n",
    "result4 = ask_and_validate(\"How can developers contribute to the Claude Skills project?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d602fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste 5: Exemplos de uso\n",
    "result5 = ask_and_validate(\"Can you provide examples of how to use Claude Skills?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9c785c",
   "metadata": {},
   "source": [
    "## Testes Adicionais\n",
    "\n",
    "Vamos testar perguntas mais específicas para validar a melhoria do sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763ba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste 6: Pergunta técnica específica\n",
    "result6 = ask_and_validate(\"What programming languages or frameworks are required for Claude Skills?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34591f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste 7: Pergunta sobre arquitetura\n",
    "result7 = ask_and_validate(\"How does Claude Skills integrate with existing applications?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba2ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste 8: Pergunta sobre licença e comunidade\n",
    "result8 = ask_and_validate(\"What is the license for Claude Skills and how can I get support?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceebcf57",
   "metadata": {},
   "source": [
    "## Persistindo o Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9b44b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()\n",
    "print(\"Vectorstore persistido com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886e98b6",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Este notebook demonstrou como:\n",
    "\n",
    "1. ✅ Carregar documentação do GitHub (README.md do Claude Skills)\n",
    "2. ✅ Dividir o documento em chunks otimizados (800 caracteres com overlap de 200)\n",
    "3. ✅ Criar embeddings usando modelo atualizado (text-embedding-3-small)\n",
    "4. ✅ Armazenar os vetores em um vectorstore (ChromaDB)\n",
    "5. ✅ Realizar buscas por similaridade e MMR para melhor diversidade\n",
    "6. ✅ Usar RAG completo com GPT-4 e prompt customizado\n",
    "7. ✅ Validar que as respostas estão de acordo com o contexto do documento original\n",
    "\n",
    "**Melhorias implementadas:**\n",
    "- ⚡ Chunks menores (800) com maior overlap (200) para preservar contexto\n",
    "- ⚡ MMR (Maximal Marginal Relevance) para recuperar documentos mais diversos\n",
    "- ⚡ Modelo GPT-4o-mini para respostas mais precisas\n",
    "- ⚡ Prompt customizado para instruir melhor o modelo\n",
    "- ⚡ Recuperação de 5 documentos ao invés de 3\n",
    "- ⚡ Modelo de embedding mais recente (text-embedding-3-small)\n",
    "\n",
    "Os testes mostraram que o sistema RAG otimizado é capaz de recuperar informações mais relevantes e gerar respostas significativamente melhores, especialmente para perguntas complexas sobre contribuição e exemplos de uso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
